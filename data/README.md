# Data Usage and Resources
## Data Format
All data in this folder is formatted into the same templates, where each sample is as follows:
```
[
{"instruction": instruction string,
"input": input string (may be empty),
"output": output string}
]
```
## alpaca_data.json
This dataset is published by [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca). It contains 52K English instruction-following samples obtained by [Self-Instruction](https://github.com/yizhongw/self-instruct) techniques.

## alpaca_data_cleaned.json
This dataset is obtained [here](https://github.com/tloen/alpaca-lora). It is a revised version of `alpaca_data.json` by stripping of various tokenization artifacts. 

## belle_data_cn.json
This dataset is published by [BELLE](https://github.com/LianjiaTech/BELLE). It contains 0.5K Chinese instruction-following samples, which is also generated by [Self-Instruction](https://github.com/yizhongw/self-instruct) techniques.

## CoT_data.json
This dataset is obtained by formatting the combination of 9 CoT datasets published by [FLAN](https://github.com/google-research/FLAN). It contains 9 CoT tasks involving 74771 samples.

## formatted_cot_data folder
This folder contains the formatted data for each CoT dataset.

## alcapa_plus_belle_data.json
This dataset is the combination of English `alpaca_data.json` and Chinese `belle_data_cn.json`.

## alcapa_plus_cot_data.json
This dataset is the combination of English `alpaca_data.json` and CoT `CoT_data.json`.

## alcapa_plus_belle_cot_data.json
This dataset is the combination of English `alpaca_data.json`, Chinese `belle_data_cn.json` and CoT `CoT_data.json`.
